{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, SimpleRNN, LayerNormalization\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "wpeRWR7yCUp2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv(\"/content/sample_data/dseats_2024_training_dataset.csv\")\n"
      ],
      "metadata": {
        "id": "P-JCggKvDQB6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the dataset\n",
        "\n",
        "# Convert 'PRODUCTION DATE' to datetime format and calculate days elapsed\n",
        "data['PRODUCTION DATE'] = pd.to_datetime(data['PRODUCTION DATE'], format='%d/%m/%Y %H:%M', errors='coerce')\n",
        "data['days_elapsed'] = (data['PRODUCTION DATE'] - data['PRODUCTION DATE'].min()).dt.days\n",
        "\n",
        "# Fill missing values in 'Choke Size' with the median\n",
        "data['Choke Size'] = data['Choke Size'].fillna(data['Choke Size'].median())\n",
        "\n",
        "# Select input and output features\n",
        "input_columns = [\n",
        "    'Downhole Pressure (PSI)',\n",
        "    'Downhole Temperature (Kelvin)',\n",
        "    'Average Tubing Pressure',\n",
        "    'Annulus Pressure (PSI)',\n",
        "    'AVG WHP (PSI)',\n",
        "    'Choke Size',\n",
        "    'days_elapsed'\n",
        "]\n",
        "output_columns = [\n",
        "    'Oil Production (stb/day)',\n",
        "    'Gas Volume (scf/day)',\n",
        "    'Water Production (stb/day)'\n",
        "]\n",
        "\n",
        "X = data[input_columns].values\n",
        "Y = data[output_columns].values\n",
        "\n",
        "\n",
        "# Normalize features\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_Y = MinMaxScaler()\n",
        "X = scaler_X.fit_transform(X)\n",
        "Y = scaler_Y.fit_transform(Y)\n",
        "\n",
        "# Reshape X for time-series input (samples, time_steps, features)\n",
        "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Confirm shapes of the processed data\n",
        "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXITiGBFDSGs",
        "outputId": "24b3ffbd-b9a8-4502-f057-1308d466c946"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5540, 1, 7), (1385, 1, 7), (5540, 3), (1385, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the RNN model for multi-output regression\n",
        "rnn_model = Sequential([\n",
        "    SimpleRNN(128, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(3)  # The output layer has as many neurons as output columns\n",
        "])\n",
        "\n",
        "rnn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the RNN model\n",
        "rnn_model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_data=(X_test, Y_test))\n",
        "\n",
        "# Make predictions\n",
        "Y_pred = rnn_model.predict(X_test)\n",
        "\n",
        "# Separate predictions into Oil, Gas, and Water\n",
        "oil_pred = Y_pred[:, 0]\n",
        "gas_pred = Y_pred[:, 1]\n",
        "water_pred = Y_pred[:, 2]\n",
        "\n",
        "oil_true = Y_test[:, 0]\n",
        "gas_true = Y_test[:, 1]\n",
        "water_true = Y_test[:, 2]\n",
        "\n",
        "# Calculate metrics for Oil\n",
        "oil_mae = mean_absolute_error(oil_true, oil_pred)\n",
        "oil_mse = mean_squared_error(oil_true, oil_pred)\n",
        "oil_rmse = oil_mse ** 0.5\n",
        "oil_r2 = r2_score(oil_true, oil_pred)\n",
        "\n",
        "# Calculate metrics for Gas\n",
        "gas_mae = mean_absolute_error(gas_true, gas_pred)\n",
        "gas_mse = mean_squared_error(gas_true, gas_pred)\n",
        "gas_rmse = gas_mse ** 0.5\n",
        "gas_r2 = r2_score(gas_true, gas_pred)\n",
        "\n",
        "# Calculate metrics for Water\n",
        "water_mae = mean_absolute_error(water_true, water_pred)\n",
        "water_mse = mean_squared_error(water_true, water_pred)\n",
        "water_rmse = water_mse ** 0.5\n",
        "water_r2 = r2_score(water_true, water_pred)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"Oil - MAE: {oil_mae:.4f}, MSE: {oil_mse:.4f}, RMSE: {oil_rmse:.4f}, R2: {oil_r2:.4f}\")\n",
        "print(f\"Gas - MAE: {gas_mae:.4f}, MSE: {gas_mse:.4f}, RMSE: {gas_rmse:.4f}, R2: {gas_r2:.4f}\")\n",
        "print(f\"Water - MAE: {water_mae:.4f}, MSE: {water_mse:.4f}, RMSE: {water_rmse:.4f}, R2: {water_r2:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN3F5Jhpy5pw",
        "outputId": "e80d9347-315c-48f7-813a-78bb905cb342"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - loss: 0.0574 - mae: 0.1729 - val_loss: 0.0139 - val_mae: 0.0863\n",
            "Epoch 2/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.0168 - mae: 0.0926 - val_loss: 0.0099 - val_mae: 0.0679\n",
            "Epoch 3/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0127 - mae: 0.0788 - val_loss: 0.0094 - val_mae: 0.0671\n",
            "Epoch 4/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0123 - mae: 0.0760 - val_loss: 0.0079 - val_mae: 0.0581\n",
            "Epoch 5/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - mae: 0.0689 - val_loss: 0.0075 - val_mae: 0.0562\n",
            "Epoch 6/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0108 - mae: 0.0697 - val_loss: 0.0072 - val_mae: 0.0544\n",
            "Epoch 7/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - mae: 0.0656 - val_loss: 0.0072 - val_mae: 0.0507\n",
            "Epoch 8/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - mae: 0.0644 - val_loss: 0.0069 - val_mae: 0.0526\n",
            "Epoch 9/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0093 - mae: 0.0651 - val_loss: 0.0062 - val_mae: 0.0480\n",
            "Epoch 10/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - mae: 0.0645 - val_loss: 0.0072 - val_mae: 0.0484\n",
            "Epoch 11/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0084 - mae: 0.0607 - val_loss: 0.0062 - val_mae: 0.0480\n",
            "Epoch 12/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 - mae: 0.0593 - val_loss: 0.0057 - val_mae: 0.0430\n",
            "Epoch 13/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0088 - mae: 0.0613 - val_loss: 0.0062 - val_mae: 0.0462\n",
            "Epoch 14/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0086 - mae: 0.0618 - val_loss: 0.0057 - val_mae: 0.0455\n",
            "Epoch 15/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0085 - mae: 0.0605 - val_loss: 0.0055 - val_mae: 0.0442\n",
            "Epoch 16/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - mae: 0.0586 - val_loss: 0.0057 - val_mae: 0.0424\n",
            "Epoch 17/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0079 - mae: 0.0584 - val_loss: 0.0057 - val_mae: 0.0462\n",
            "Epoch 18/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0072 - mae: 0.0557 - val_loss: 0.0058 - val_mae: 0.0448\n",
            "Epoch 19/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 - mae: 0.0575 - val_loss: 0.0056 - val_mae: 0.0456\n",
            "Epoch 20/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - mae: 0.0606 - val_loss: 0.0057 - val_mae: 0.0478\n",
            "Epoch 21/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 - mae: 0.0582 - val_loss: 0.0048 - val_mae: 0.0390\n",
            "Epoch 22/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 - mae: 0.0570 - val_loss: 0.0051 - val_mae: 0.0433\n",
            "Epoch 23/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0077 - mae: 0.0578 - val_loss: 0.0051 - val_mae: 0.0412\n",
            "Epoch 24/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mae: 0.0562 - val_loss: 0.0048 - val_mae: 0.0400\n",
            "Epoch 25/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 - mae: 0.0568 - val_loss: 0.0056 - val_mae: 0.0447\n",
            "Epoch 26/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - mae: 0.0555 - val_loss: 0.0053 - val_mae: 0.0424\n",
            "Epoch 27/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - mae: 0.0558 - val_loss: 0.0044 - val_mae: 0.0377\n",
            "Epoch 28/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0065 - mae: 0.0545 - val_loss: 0.0046 - val_mae: 0.0362\n",
            "Epoch 29/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0070 - mae: 0.0557 - val_loss: 0.0046 - val_mae: 0.0382\n",
            "Epoch 30/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mae: 0.0556 - val_loss: 0.0049 - val_mae: 0.0401\n",
            "Epoch 31/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0070 - mae: 0.0554 - val_loss: 0.0051 - val_mae: 0.0407\n",
            "Epoch 32/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0067 - mae: 0.0547 - val_loss: 0.0045 - val_mae: 0.0372\n",
            "Epoch 33/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0544 - val_loss: 0.0044 - val_mae: 0.0364\n",
            "Epoch 34/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0068 - mae: 0.0547 - val_loss: 0.0055 - val_mae: 0.0451\n",
            "Epoch 35/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0065 - mae: 0.0537 - val_loss: 0.0042 - val_mae: 0.0380\n",
            "Epoch 36/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0066 - mae: 0.0534 - val_loss: 0.0044 - val_mae: 0.0382\n",
            "Epoch 37/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0061 - mae: 0.0530 - val_loss: 0.0050 - val_mae: 0.0416\n",
            "Epoch 38/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0067 - mae: 0.0533 - val_loss: 0.0041 - val_mae: 0.0358\n",
            "Epoch 39/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0063 - mae: 0.0529 - val_loss: 0.0042 - val_mae: 0.0374\n",
            "Epoch 40/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0063 - mae: 0.0525 - val_loss: 0.0040 - val_mae: 0.0377\n",
            "Epoch 41/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - mae: 0.0531 - val_loss: 0.0045 - val_mae: 0.0401\n",
            "Epoch 42/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0065 - mae: 0.0539 - val_loss: 0.0041 - val_mae: 0.0363\n",
            "Epoch 43/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0061 - mae: 0.0520 - val_loss: 0.0038 - val_mae: 0.0353\n",
            "Epoch 44/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - mae: 0.0535 - val_loss: 0.0040 - val_mae: 0.0341\n",
            "Epoch 45/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - mae: 0.0522 - val_loss: 0.0036 - val_mae: 0.0338\n",
            "Epoch 46/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - mae: 0.0520 - val_loss: 0.0060 - val_mae: 0.0468\n",
            "Epoch 47/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0549 - val_loss: 0.0043 - val_mae: 0.0389\n",
            "Epoch 48/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0059 - mae: 0.0511 - val_loss: 0.0041 - val_mae: 0.0351\n",
            "Epoch 49/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0064 - mae: 0.0518 - val_loss: 0.0036 - val_mae: 0.0334\n",
            "Epoch 50/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - mae: 0.0515 - val_loss: 0.0035 - val_mae: 0.0320\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "Oil - MAE: 0.0325, MSE: 0.0040, RMSE: 0.0634, R2: 0.9302\n",
            "Gas - MAE: 0.0332, MSE: 0.0040, RMSE: 0.0632, R2: 0.9278\n",
            "Water - MAE: 0.0303, MSE: 0.0024, RMSE: 0.0487, R2: 0.9492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the LSTM model\n",
        "lstm_model = Sequential([\n",
        "    LSTM(64, activation='tanh', return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(Y_train.shape[1])  # Output features: Oil, Gas, Water\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "lstm_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "lstm_model.fit(\n",
        "    X_train, Y_train,\n",
        "    validation_data=(X_test, Y_test),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Make predictions\n",
        "Y_pred = lstm_model.predict(X_test)\n",
        "\n",
        "# Separate predictions for Oil, Gas, and Water\n",
        "oil_pred = Y_pred[:, 0]\n",
        "gas_pred = Y_pred[:, 1]\n",
        "water_pred = Y_pred[:, 2]\n",
        "\n",
        "oil_true = Y_test[:, 0]\n",
        "gas_true = Y_test[:, 1]\n",
        "water_true = Y_test[:, 2]\n",
        "\n",
        "# Calculate metrics for Oil\n",
        "oil_mae = mean_absolute_error(oil_true, oil_pred)\n",
        "oil_mse = mean_squared_error(oil_true, oil_pred)\n",
        "oil_rmse = oil_mse ** 0.5\n",
        "r2 = r2_score(oil_true, oil_pred)\n",
        "\n",
        "# Calculate metrics for Gas\n",
        "gas_mae = mean_absolute_error(gas_true, gas_pred)\n",
        "gas_mse = mean_squared_error(gas_true, gas_pred)\n",
        "gas_rmse = gas_mse ** 0.5\n",
        "r2 = r2_score(gas_true, gas_pred)\n",
        "\n",
        "# Calculate metrics for Water\n",
        "water_mae = mean_absolute_error(water_true, water_pred)\n",
        "water_mse = mean_squared_error(water_true, water_pred)\n",
        "water_rmse = water_mse ** 0.5\n",
        "r2 = r2_score(water_true, water_pred)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"Oil - MAE: {oil_mae:.4f}, MSE: {oil_mse:.4f}, RMSE: {oil_rmse:.4f}, R2: {r2:.4f} \")\n",
        "print(f\"Gas - MAE: {gas_mae:.4f}, MSE: {gas_mse:.4f}, RMSE: {gas_rmse:.4f}, R2:{r2:.4f}\")\n",
        "print(f\"Water - MAE: {water_mae:.4f}, MSE: {water_mse:.4f}, RMSE: {water_rmse:.4f}, R2: {r2:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj3uwI6uCiri",
        "outputId": "2808422f-e803-462d-98ed-9c66d52db4f3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 - 3s - 16ms/step - loss: 0.0360 - mae: 0.1442 - val_loss: 0.0170 - val_mae: 0.0943\n",
            "Epoch 2/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0137 - mae: 0.0832 - val_loss: 0.0106 - val_mae: 0.0716\n",
            "Epoch 3/100\n",
            "174/174 - 2s - 9ms/step - loss: 0.0103 - mae: 0.0712 - val_loss: 0.0088 - val_mae: 0.0637\n",
            "Epoch 4/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0082 - mae: 0.0623 - val_loss: 0.0087 - val_mae: 0.0624\n",
            "Epoch 5/100\n",
            "174/174 - 1s - 6ms/step - loss: 0.0077 - mae: 0.0587 - val_loss: 0.0073 - val_mae: 0.0554\n",
            "Epoch 6/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0072 - mae: 0.0557 - val_loss: 0.0069 - val_mae: 0.0514\n",
            "Epoch 7/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0067 - mae: 0.0527 - val_loss: 0.0066 - val_mae: 0.0493\n",
            "Epoch 8/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0066 - mae: 0.0520 - val_loss: 0.0066 - val_mae: 0.0472\n",
            "Epoch 9/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0063 - mae: 0.0496 - val_loss: 0.0062 - val_mae: 0.0456\n",
            "Epoch 10/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0062 - mae: 0.0491 - val_loss: 0.0063 - val_mae: 0.0459\n",
            "Epoch 11/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0059 - mae: 0.0477 - val_loss: 0.0066 - val_mae: 0.0475\n",
            "Epoch 12/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0058 - mae: 0.0468 - val_loss: 0.0061 - val_mae: 0.0466\n",
            "Epoch 13/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0056 - mae: 0.0466 - val_loss: 0.0058 - val_mae: 0.0415\n",
            "Epoch 14/100\n",
            "174/174 - 1s - 6ms/step - loss: 0.0055 - mae: 0.0443 - val_loss: 0.0059 - val_mae: 0.0405\n",
            "Epoch 15/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0056 - mae: 0.0459 - val_loss: 0.0058 - val_mae: 0.0417\n",
            "Epoch 16/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0053 - mae: 0.0439 - val_loss: 0.0057 - val_mae: 0.0412\n",
            "Epoch 17/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0054 - mae: 0.0448 - val_loss: 0.0055 - val_mae: 0.0421\n",
            "Epoch 18/100\n",
            "174/174 - 1s - 6ms/step - loss: 0.0053 - mae: 0.0439 - val_loss: 0.0063 - val_mae: 0.0431\n",
            "Epoch 19/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0052 - mae: 0.0432 - val_loss: 0.0059 - val_mae: 0.0444\n",
            "Epoch 20/100\n",
            "174/174 - 1s - 6ms/step - loss: 0.0050 - mae: 0.0426 - val_loss: 0.0056 - val_mae: 0.0436\n",
            "Epoch 21/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0054 - mae: 0.0446 - val_loss: 0.0051 - val_mae: 0.0375\n",
            "Epoch 22/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0049 - mae: 0.0413 - val_loss: 0.0053 - val_mae: 0.0411\n",
            "Epoch 23/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0047 - mae: 0.0401 - val_loss: 0.0057 - val_mae: 0.0443\n",
            "Epoch 24/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0048 - mae: 0.0411 - val_loss: 0.0050 - val_mae: 0.0394\n",
            "Epoch 25/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0047 - mae: 0.0404 - val_loss: 0.0056 - val_mae: 0.0407\n",
            "Epoch 26/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0047 - mae: 0.0399 - val_loss: 0.0049 - val_mae: 0.0360\n",
            "Epoch 27/100\n",
            "174/174 - 2s - 12ms/step - loss: 0.0046 - mae: 0.0392 - val_loss: 0.0047 - val_mae: 0.0364\n",
            "Epoch 28/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0047 - mae: 0.0404 - val_loss: 0.0059 - val_mae: 0.0455\n",
            "Epoch 29/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0046 - mae: 0.0396 - val_loss: 0.0047 - val_mae: 0.0369\n",
            "Epoch 30/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0046 - mae: 0.0395 - val_loss: 0.0044 - val_mae: 0.0360\n",
            "Epoch 31/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0047 - mae: 0.0402 - val_loss: 0.0046 - val_mae: 0.0376\n",
            "Epoch 32/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0044 - mae: 0.0388 - val_loss: 0.0046 - val_mae: 0.0366\n",
            "Epoch 33/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0045 - mae: 0.0387 - val_loss: 0.0048 - val_mae: 0.0374\n",
            "Epoch 34/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0044 - mae: 0.0389 - val_loss: 0.0045 - val_mae: 0.0362\n",
            "Epoch 35/100\n",
            "174/174 - 1s - 6ms/step - loss: 0.0045 - mae: 0.0392 - val_loss: 0.0058 - val_mae: 0.0417\n",
            "Epoch 36/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0045 - mae: 0.0384 - val_loss: 0.0042 - val_mae: 0.0349\n",
            "Epoch 37/100\n",
            "174/174 - 2s - 12ms/step - loss: 0.0044 - mae: 0.0390 - val_loss: 0.0046 - val_mae: 0.0373\n",
            "Epoch 38/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0044 - mae: 0.0384 - val_loss: 0.0043 - val_mae: 0.0350\n",
            "Epoch 39/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0044 - mae: 0.0386 - val_loss: 0.0043 - val_mae: 0.0354\n",
            "Epoch 40/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0042 - mae: 0.0374 - val_loss: 0.0046 - val_mae: 0.0384\n",
            "Epoch 41/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0041 - mae: 0.0373 - val_loss: 0.0046 - val_mae: 0.0381\n",
            "Epoch 42/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0042 - mae: 0.0368 - val_loss: 0.0044 - val_mae: 0.0356\n",
            "Epoch 43/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0043 - mae: 0.0382 - val_loss: 0.0043 - val_mae: 0.0340\n",
            "Epoch 44/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0042 - mae: 0.0371 - val_loss: 0.0044 - val_mae: 0.0373\n",
            "Epoch 45/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0043 - mae: 0.0379 - val_loss: 0.0044 - val_mae: 0.0362\n",
            "Epoch 46/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0041 - mae: 0.0374 - val_loss: 0.0049 - val_mae: 0.0413\n",
            "Epoch 47/100\n",
            "174/174 - 2s - 14ms/step - loss: 0.0043 - mae: 0.0381 - val_loss: 0.0043 - val_mae: 0.0349\n",
            "Epoch 48/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0041 - mae: 0.0371 - val_loss: 0.0046 - val_mae: 0.0372\n",
            "Epoch 49/100\n",
            "174/174 - 1s - 6ms/step - loss: 0.0040 - mae: 0.0358 - val_loss: 0.0042 - val_mae: 0.0339\n",
            "Epoch 50/100\n",
            "174/174 - 1s - 6ms/step - loss: 0.0041 - mae: 0.0366 - val_loss: 0.0044 - val_mae: 0.0349\n",
            "Epoch 51/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0041 - mae: 0.0372 - val_loss: 0.0046 - val_mae: 0.0358\n",
            "Epoch 52/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0042 - mae: 0.0372 - val_loss: 0.0045 - val_mae: 0.0360\n",
            "Epoch 53/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0042 - mae: 0.0371 - val_loss: 0.0044 - val_mae: 0.0356\n",
            "Epoch 54/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0040 - mae: 0.0359 - val_loss: 0.0041 - val_mae: 0.0340\n",
            "Epoch 55/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0039 - mae: 0.0359 - val_loss: 0.0043 - val_mae: 0.0327\n",
            "Epoch 56/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0043 - mae: 0.0373 - val_loss: 0.0042 - val_mae: 0.0355\n",
            "Epoch 57/100\n",
            "174/174 - 2s - 11ms/step - loss: 0.0040 - mae: 0.0362 - val_loss: 0.0041 - val_mae: 0.0324\n",
            "Epoch 58/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0040 - mae: 0.0357 - val_loss: 0.0042 - val_mae: 0.0345\n",
            "Epoch 59/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0039 - mae: 0.0355 - val_loss: 0.0043 - val_mae: 0.0365\n",
            "Epoch 60/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0039 - mae: 0.0358 - val_loss: 0.0047 - val_mae: 0.0364\n",
            "Epoch 61/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0040 - mae: 0.0359 - val_loss: 0.0040 - val_mae: 0.0319\n",
            "Epoch 62/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0039 - mae: 0.0356 - val_loss: 0.0042 - val_mae: 0.0341\n",
            "Epoch 63/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0040 - mae: 0.0365 - val_loss: 0.0045 - val_mae: 0.0373\n",
            "Epoch 64/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0040 - mae: 0.0364 - val_loss: 0.0046 - val_mae: 0.0423\n",
            "Epoch 65/100\n",
            "174/174 - 2s - 10ms/step - loss: 0.0039 - mae: 0.0356 - val_loss: 0.0038 - val_mae: 0.0316\n",
            "Epoch 66/100\n",
            "174/174 - 2s - 12ms/step - loss: 0.0038 - mae: 0.0350 - val_loss: 0.0038 - val_mae: 0.0347\n",
            "Epoch 67/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0038 - mae: 0.0349 - val_loss: 0.0038 - val_mae: 0.0344\n",
            "Epoch 68/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0038 - mae: 0.0345 - val_loss: 0.0050 - val_mae: 0.0361\n",
            "Epoch 69/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0039 - mae: 0.0352 - val_loss: 0.0041 - val_mae: 0.0343\n",
            "Epoch 70/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0040 - mae: 0.0358 - val_loss: 0.0045 - val_mae: 0.0354\n",
            "Epoch 71/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0038 - mae: 0.0352 - val_loss: 0.0049 - val_mae: 0.0358\n",
            "Epoch 72/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0039 - mae: 0.0354 - val_loss: 0.0041 - val_mae: 0.0363\n",
            "Epoch 73/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0037 - mae: 0.0343 - val_loss: 0.0039 - val_mae: 0.0323\n",
            "Epoch 74/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0038 - mae: 0.0352 - val_loss: 0.0041 - val_mae: 0.0316\n",
            "Epoch 75/100\n",
            "174/174 - 2s - 9ms/step - loss: 0.0037 - mae: 0.0337 - val_loss: 0.0037 - val_mae: 0.0318\n",
            "Epoch 76/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0037 - mae: 0.0340 - val_loss: 0.0037 - val_mae: 0.0317\n",
            "Epoch 77/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0038 - mae: 0.0347 - val_loss: 0.0036 - val_mae: 0.0316\n",
            "Epoch 78/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0039 - mae: 0.0347 - val_loss: 0.0039 - val_mae: 0.0353\n",
            "Epoch 79/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0037 - mae: 0.0337 - val_loss: 0.0036 - val_mae: 0.0299\n",
            "Epoch 80/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0038 - mae: 0.0351 - val_loss: 0.0041 - val_mae: 0.0327\n",
            "Epoch 81/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0037 - mae: 0.0348 - val_loss: 0.0035 - val_mae: 0.0294\n",
            "Epoch 82/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0038 - mae: 0.0343 - val_loss: 0.0041 - val_mae: 0.0360\n",
            "Epoch 83/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0038 - mae: 0.0347 - val_loss: 0.0041 - val_mae: 0.0329\n",
            "Epoch 84/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0036 - mae: 0.0338 - val_loss: 0.0034 - val_mae: 0.0308\n",
            "Epoch 85/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0037 - mae: 0.0339 - val_loss: 0.0044 - val_mae: 0.0336\n",
            "Epoch 86/100\n",
            "174/174 - 2s - 12ms/step - loss: 0.0037 - mae: 0.0340 - val_loss: 0.0040 - val_mae: 0.0341\n",
            "Epoch 87/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0036 - mae: 0.0340 - val_loss: 0.0035 - val_mae: 0.0302\n",
            "Epoch 88/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0036 - mae: 0.0329 - val_loss: 0.0042 - val_mae: 0.0321\n",
            "Epoch 89/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0036 - mae: 0.0336 - val_loss: 0.0038 - val_mae: 0.0320\n",
            "Epoch 90/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0037 - mae: 0.0343 - val_loss: 0.0037 - val_mae: 0.0322\n",
            "Epoch 91/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0036 - mae: 0.0336 - val_loss: 0.0053 - val_mae: 0.0373\n",
            "Epoch 92/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0036 - mae: 0.0336 - val_loss: 0.0036 - val_mae: 0.0300\n",
            "Epoch 93/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0036 - mae: 0.0331 - val_loss: 0.0039 - val_mae: 0.0335\n",
            "Epoch 94/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0036 - mae: 0.0334 - val_loss: 0.0038 - val_mae: 0.0312\n",
            "Epoch 95/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0036 - mae: 0.0329 - val_loss: 0.0038 - val_mae: 0.0317\n",
            "Epoch 96/100\n",
            "174/174 - 1s - 8ms/step - loss: 0.0035 - mae: 0.0329 - val_loss: 0.0039 - val_mae: 0.0345\n",
            "Epoch 97/100\n",
            "174/174 - 2s - 12ms/step - loss: 0.0036 - mae: 0.0335 - val_loss: 0.0037 - val_mae: 0.0307\n",
            "Epoch 98/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0037 - mae: 0.0338 - val_loss: 0.0035 - val_mae: 0.0317\n",
            "Epoch 99/100\n",
            "174/174 - 1s - 5ms/step - loss: 0.0036 - mae: 0.0336 - val_loss: 0.0035 - val_mae: 0.0298\n",
            "Epoch 100/100\n",
            "174/174 - 1s - 7ms/step - loss: 0.0036 - mae: 0.0335 - val_loss: 0.0035 - val_mae: 0.0288\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Oil - MAE: 0.0299, MSE: 0.0041, RMSE: 0.0641, R2: 0.9501 \n",
            "Gas - MAE: 0.0300, MSE: 0.0040, RMSE: 0.0629, R2:0.9501\n",
            "Water - MAE: 0.0264, MSE: 0.0023, RMSE: 0.0483, R2: 0.9501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9smcHATz6ruX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iTFgLAeI4ncH"
      }
    }
  ]
}